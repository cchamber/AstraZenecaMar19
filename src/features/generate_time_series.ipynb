{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataframes with sample and study counts over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def query_tree(tdf,search_term):\n",
    "    mesh_list = []\n",
    "    tlist = tdf[tdf.mesh_id==search_term].mesh_treenumbers.tolist()\n",
    "    for it in tlist:\n",
    "        nchar = len(it)\n",
    "        mesh = tdf[tdf.mesh_treenumbers.str[:nchar]==it].mesh_id.to_list()\n",
    "        mesh_list += mesh\n",
    "    return np.unique(mesh_list)\n",
    "\n",
    "def query_tags(tadf, mesh_list, time_range):\n",
    "    min_date = int(time_range[0])\n",
    "    max_date = int(time_range[1])\n",
    "    match_df = tadf.loc[(np.isin(tadf.mesh_id, mesh_list))&(tadf.year<=max_date)&(tadf.year>=min_date),:] # find matches for the mesh list\n",
    "    return match_df\n",
    "\n",
    "def get_counts_per_year(matchdf,time_range):\n",
    "    # counts per year\n",
    "    ts = matchdf[['geo_id', 'year', 'aux']].groupby(['geo_id', 'year']).mean().reset_index()[['geo_id', 'year']]\n",
    "    cpy = ts.groupby('year').size().reset_index(name='c')\n",
    "    # make sure that all years are in df\n",
    "    all_years = pd.DataFrame(pd.Series(np.arange(int(time_range[0]), int(time_range[1]),1)), columns = ['year'])\n",
    "    all_years['aux'] = 1\n",
    "    cpy_merge = pd.merge(all_years, cpy, on = 'year', how='outer')\n",
    "    cpy_merge = cpy_merge.drop('aux', axis = 1)\n",
    "    cpy_merge.loc[cpy_merge.c.isnull(), 'c'] = 0\n",
    "    return cpy_merge\n",
    "\n",
    "def get_samples_per_year(matchdf,time_range):\n",
    "    ts = matchdf.groupby(['geo_id', 'year']).nsamples.mean().reset_index()\n",
    "    spy = ts.groupby('year').nsamples.sum().reset_index()\n",
    "    all_years = pd.DataFrame(pd.Series(np.arange(int(time_range[0]), int(time_range[1]),1)), columns = ['year'])\n",
    "    all_years['aux'] = 1\n",
    "    spy = pd.merge(all_years, spy, on = 'year', how='outer')\n",
    "    spy = spy.drop('aux', axis = 1)\n",
    "    spy.loc[spy.nsamples.isnull(), 'nsamples'] = 0\n",
    "    return spy\n",
    "\n",
    "def normalise_it(df):\n",
    "    df['c_norm'] = (df.c)/(df.c.sum())\n",
    "    return df\n",
    "\n",
    "def add_all_years(p, time_range):\n",
    "    all_years = pd.DataFrame(pd.Series(np.arange(int(time_range[0]), int(time_range[1]),1)), columns = ['year'])\n",
    "    all_years['aux'] = 1\n",
    "    mesh = p.mesh_heading.unique()[0]\n",
    "    p_merge = pd.merge(all_years, p, on = 'year', how='outer')\n",
    "    p_merge = p_merge.drop('aux', axis = 1)\n",
    "    p_merge.loc[p_merge.n.isnull(), 'n'] = 0\n",
    "    p_merge.loc[p_merge.mesh_heading.isnull(), 'mesh_heading'] = mesh\n",
    "    return p_merge\n",
    "\n",
    "\n",
    "path = '../../data/final'\n",
    "\n",
    "# load tree\n",
    "tree_file = 'mesh.pkl'\n",
    "trdf = pd.read_pickle(os.path.join(path, tree_file))\n",
    "\n",
    "# load tags\n",
    "tag_file ='geo_filtered.pkl'\n",
    "tadf = pd.read_pickle(os.path.join(path, tag_file))\n",
    "tadf['year'] = (tadf.date.str[:4]).astype(int) # year\n",
    "tadf = pd.merge(tadf,trdf[['mesh_id', 'mesh_treenumbers']], on='mesh_id', how='left')\n",
    "\n",
    "# load top topics based on n series\n",
    "count_file ='meshids_rankedby_NSeries.pkl'\n",
    "countsdf = pd.read_pickle(os.path.join(path,count_file))\n",
    "countsdf = pd.merge(countsdf,trdf, on='mesh_id', how='left')\n",
    "countsdf = countsdf.loc[np.isin(countsdf.category, ['C'])].reset_index(drop=True)\n",
    "\n",
    "min_year = '2000'\n",
    "max_year = '2017'\n",
    "time_range = [min_year, max_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntopdisease = 200\n",
    "\n",
    "mesh_ids = countsdf.loc[:ntopdisease,'mesh_id'].to_list()\n",
    "\n",
    "top_d_df = trdf.loc[np.isin(trdf.mesh_id, mesh_ids),:]\n",
    "# build 3 levels of hierarchy\n",
    "top_d_df['level'] = top_d_df.mesh_treenumbers.str.len()\n",
    "top_d_df.loc[top_d_df['level']<4,'level'] = 1\n",
    "top_d_df.loc[(top_d_df['level']>=4) & (top_d_df['level']<=20),'level'] = 2\n",
    "top_d_df.loc[top_d_df['level']>20,'level'] = 3\n",
    "top_d_df = top_d_df.reset_index(drop=True)\n",
    "\n",
    "mesh_ids = top_d_df.mesh_id.to_list()\n",
    "mesh_headings = top_d_df.mesh_heading.to_list()\n",
    "\n",
    "countdf = pd.DataFrame()\n",
    "sampledf = pd.DataFrame()\n",
    "for iid, ihead in zip(mesh_ids, mesh_headings):\n",
    "    mesh_list = query_tree(trdf,iid)\n",
    "    matchdf = query_tags(tadf, mesh_list, time_range)\n",
    "    matchdf['year'] = matchdf.date.astype(str).str[:4].astype(int)\n",
    "    matchdf['aux'] = 1\n",
    "    cpy = get_counts_per_year(matchdf,time_range); cpy['mesh_id'] = iid; cpy['mesh_heading'] = ihead; \n",
    "    spy = get_samples_per_year(matchdf,time_range); spy['mesh_id'] = iid; spy['mesh_heading'] = ihead;\n",
    "    countdf = countdf.append(cpy)\n",
    "    sampledf = sampledf.append(spy)\n",
    "\n",
    "# add parent column to df\n",
    "n = 1 # start with level 1\n",
    "l1_tree_list = top_d_df.loc[top_d_df.level==n].mesh_treenumbers.tolist()\n",
    "l1_mesh_headings = top_d_df.loc[top_d_df.level==n].mesh_heading.tolist()\n",
    "for itree, iheading in zip(l1_tree_list, l1_mesh_headings):\n",
    "    nchar = len(itree)\n",
    "    top_d_df.loc[(top_d_df.level==n+1)&(top_d_df.mesh_treenumbers.str[:nchar]==itree),'parent'] = iheading \n",
    "top_d_df = pd.merge(countsdf[['mesh_id', 'n']],top_d_df, on=['mesh_id'], how='inner')\n",
    "top_d_df = top_d_df.sort_values('n', ascending=False)\n",
    "\n",
    "sampledf = sampledf.rename(index=str, columns = {'nsamples':'c'})\n",
    "\n",
    "top_d_df.to_pickle('../../data/final/top_diseases_for_plotting.pkl')\n",
    "countdf.to_pickle('../../data/final/countsbyyear_for_plotting.pkl')\n",
    "sampledf.to_pickle('../../data/final/samplesbyyear_for_plotting.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
