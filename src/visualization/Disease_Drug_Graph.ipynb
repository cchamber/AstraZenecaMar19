{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np \n",
    "\n",
    "# Import Network X\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths for in.out files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of IN-labels\n",
    "mesh_path = '../../data/final/mesh.pkl'\n",
    "\n",
    "# Path for IN-tags\n",
    "geo_path = '../../data/final/geo.pkl'\n",
    "\n",
    "# Path for IN-tags-restful\n",
    "rest_path = '../../data/final/geo_restful_chem.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read geo_df and mesh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MeSH\n",
    "mesh_df = pd.read_pickle(mesh_path)\n",
    "\n",
    "# Read GEO\n",
    "geo_df = pd.read_pickle(geo_path)\n",
    "\n",
    "# Read Restful API\n",
    "rest_df = pd.read_pickle(rest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Diseases\n",
    "geo_C = geo_df[geo_df['category']=='C']\n",
    "geo_D = geo_df[geo_df['category']=='D']\n",
    "\n",
    "# Find new tags for drugs\n",
    "geo_D_rest = pd.merge(\n",
    "    geo_D, \n",
    "    rest_df['mesh_id disease_tag_from_tagger'.split()].drop_duplicates(), \n",
    "    how='inner', \n",
    "    on='mesh_id')\n",
    "geo_D_rest.drop(columns='mesh_heading', inplace=True)\n",
    "geo_D_rest = geo_D_rest['geo_id nsamples date mesh_id disease_tag_from_tagger category method'.split()]\n",
    "geo_D_rest.rename(columns={'disease_tag_from_tagger':'mesh_heading'}, inplace=True)\n",
    "\n",
    "# Concatenate them into new geo_df\n",
    "geo_df = pd.concat([geo_C, geo_D_rest])\n",
    "\n",
    "# Echo\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute category-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct grand AstraZeneca dataframe\n",
    "az_df = pd.merge(geo_df, mesh_df, on='mesh_id')\n",
    "\n",
    "# Drop extra columns from merge\n",
    "az_df.drop(columns='mesh_heading_y category_y method'.split(), inplace=True)\n",
    "\n",
    "# Rename merge column\n",
    "az_df.rename(columns={'mesh_heading_x':'mesh_heading'}, inplace=True)\n",
    "\n",
    "# Calculate category - Again\n",
    "az_df['category']=az_df['mesh_treenumbers'].str.split('.').str[0].str[0]\n",
    "\n",
    "# Report on propperly classified MeSH-ids category-wise\n",
    "Propper_Tags = list(az_df['category_x']==az_df['category']).count(True)\n",
    "Total_Tags = az_df['category_x'].shape[0]\n",
    "print('Correctly categorized MeSH ids: {:4.1f}%'.format(100*Propper_Tags/Total_Tags))\n",
    "\n",
    "# Calculate category depth\n",
    "az_df['depth']=az_df['mesh_treenumbers'].str.split('.').str.len()\n",
    "\n",
    "# Drop old-category column\n",
    "az_df.drop(columns='category_x'.split(), inplace=True)\n",
    "\n",
    "# Echo\n",
    "az_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Clean geo DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct date filter \n",
    "mask_date = az_df['date']==az_df['date'] # Take all studies\n",
    "\n",
    "# Construct category filter\n",
    "mask_category = ((az_df['category']=='C') | (az_df['category']=='D')) # Drugs and Diseases\n",
    "\n",
    "# Construct mask to filter high-general categories\n",
    "mask_depth = True #((az_df['depth']>=2) & (az_df['depth']>=2))\n",
    "\n",
    "# Construct mask to avoid specific categories\n",
    "mask_c23 = ~az_df['mesh_treenumbers'].str.startswith('C23', na=False)\n",
    "mask_avoid_cats = mask_c23\n",
    "\n",
    "# Apply filters\n",
    "filtered_geo_df = pd.DataFrame(az_df[mask_date & mask_category & mask_depth & mask_avoid_cats])\n",
    "\n",
    "# Eliminate filterning columns\n",
    "filtered_geo_df.drop(columns='date mesh_treenumbers depth'.split(), inplace=True)\n",
    "\n",
    "# Drop NaNs\n",
    "filtered_geo_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "filtered_geo_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Only select summaries with +1 tag\n",
    "tags_by_summary = filtered_geo_df['geo_id mesh_id'.split()].groupby('geo_id').count().reset_index() # Count tags per summary\n",
    "good_summaries = tags_by_summary[tags_by_summary['mesh_id']>1] # Select abstracts with more than one tag\n",
    "clean_geo = pd.merge(filtered_geo_df, good_summaries, on='geo_id') # Inner Join\n",
    "clean_geo = clean_geo.drop(columns='mesh_id_y') # Drop column from inner join\n",
    "clean_geo = clean_geo.rename(columns={'mesh_id_x':'mesh_id'}) # Rename key column\n",
    "\n",
    "# Write info\n",
    "print('Number of Records: ',clean_geo.shape[0])\n",
    "\n",
    "# Echo\n",
    "clean_geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Disease-Drug Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant columns\n",
    "nodes = pd.DataFrame(clean_geo['mesh_id category mesh_heading'.split()])\n",
    "\n",
    "# Drop duplicates\n",
    "nodes.drop_duplicates(inplace=True, keep='first')\n",
    "\n",
    "# Echo\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct all-with-all links inside same geoid-nsample-date record\n",
    "links = pd.merge(clean_geo, clean_geo, on='geo_id nsamples'.split())\n",
    "\n",
    "# Rename to Source-Target\n",
    "links.rename(columns={'mesh_id_x':'source', 'mesh_id_y':'target'}, inplace=True)\n",
    "\n",
    "# Delete self-linkage\n",
    "links.drop(links[links['source']==links['target']].index, inplace=True)\n",
    "\n",
    "# Collapse repetitions while calculating weights\n",
    "edges = links.groupby('source target'.split()).sum().reset_index()\n",
    "\n",
    "# Rename sum(nsamples) to 'weight'\n",
    "edges.rename(columns={'nsamples':'weight'}, inplace=True)\n",
    "\n",
    "# Account for mirror-duplicates\n",
    "edges['weight']/=2\n",
    "\n",
    "# Normalize weights\n",
    "edges['weight']/=edges['weight'].max()\n",
    "\n",
    "# Head\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Directed Graph\n",
    "dd = nx.from_pandas_edgelist(edges, \n",
    "                             source='source', \n",
    "                             target='target', \n",
    "                             edge_attr='weight', \n",
    "                             create_using=nx.DiGraph()\n",
    "                            )\n",
    "\n",
    "# Transform to undirected graph\n",
    "dd = nx.to_undirected(dd)\n",
    "\n",
    "# Add nodes attributes - Category\n",
    "nx.set_node_attributes(dd, nodes['mesh_id category'.split()].set_index('mesh_id').to_dict()['category'], 'category')\n",
    "\n",
    "# Add nodes attributes - Mesh Heading\n",
    "nx.set_node_attributes(dd, nodes['mesh_id mesh_heading'.split()].set_index('mesh_id').to_dict()['mesh_heading'], 'mesh_heading')\n",
    "\n",
    "# Save as pickle\n",
    "nx.write_gpickle(dd,'Gephi_DD.pkl')\n",
    "\n",
    "# Save to gephi\n",
    "nx.write_gexf(dd,'Gephi_DD.gexf')\n",
    "\n",
    "# Echo info\n",
    "print('  Size (Nodes): ', dd.size())\n",
    "print(' Order (Edges): ', dd.order())\n",
    "print(' Graph Density: ', nx.density(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some useful functions over the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(graph):\n",
    "    \"\"\"\n",
    "    Get a dictionary with the categories of all the nodes\n",
    "    \"\"\"\n",
    "    return nx.get_node_attributes(graph, 'category')\n",
    "   \n",
    "    \n",
    "def get_mesh_headings(graph):\n",
    "    \"\"\"\n",
    "    Get a dictionary with the mesh-headings of all the nodes\n",
    "    \"\"\"\n",
    "    return nx.get_node_attributes(graph, 'mesh_heading')\n",
    "    \n",
    "\n",
    "def get_neighbors(graph, node, cats):\n",
    "    \"\"\"\n",
    "    Get the neighbors of the node such that they have the same/opposite category\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define empty lists\n",
    "    same = list()\n",
    "    oppo = list()\n",
    "        \n",
    "    # Select only those with same category\n",
    "    for neigh in nx.neighbors(dd, node):\n",
    "            \n",
    "        # Check for same neighbors\n",
    "        if cats[neigh]==cats[node]:\n",
    "            same.append(neigh)\n",
    "        else:\n",
    "            oppo.append(neigh)\n",
    "                \n",
    "    # Return the tuples same and oppo\n",
    "    return same, oppo\n",
    "    \n",
    "    \n",
    "def get_top(dictionary_metric, top):\n",
    "    \"\"\"\n",
    "    Find the top-n nodes according to some metric\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the items in the metric dictionary\n",
    "    items = list(dictionary_metric.items())\n",
    "    \n",
    "    # Sort them out\n",
    "    items.sort(reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    # Return the keys\n",
    "    return list(map(lambda x:x[0], items[:top]))\n",
    "\n",
    "\n",
    "def get_only(graph, cats, specific_category):\n",
    "    \"\"\"\n",
    "    Select the nodes of the graph where category==category and returns a subgraph\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define empty list\n",
    "    only_nodes = list()\n",
    "    \n",
    "    # Cycle through the nodes\n",
    "    for node in graph.nodes():\n",
    "        if cats[node]==specific_category:\n",
    "            only_nodes.append(node)\n",
    "    \n",
    "    # Return the subgraph\n",
    "    return nx.subgraph(graph, only_nodes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomend drugs for top diseases ['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read full graph\n",
    "ee = nx.read_gpickle('Gephi_DD.pkl')\n",
    "\n",
    "# Read categories and labels\n",
    "cats = get_categories(graph=ee)\n",
    "labs = get_mesh_headings(graph=ee)\n",
    "\n",
    "# Choose only disease-nodes\n",
    "diseases = get_only(graph=ee, cats=cats, specific_category='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs stats on diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disease eigenvector centrality\n",
    "diseases_eig = nx.eigenvector_centrality(diseases, max_iter=500, weight='weight')\n",
    "\n",
    "# Disease PageRank \n",
    "diseases_pgn = nx.pagerank(diseases, alpha=0.9, weight='weight')\n",
    "\n",
    "# Disease Degree \n",
    "diseases_deg = nx.degree_centrality(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose n-top disease nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top-diseases\n",
    "top = 100\n",
    "top_eig = get_top(dictionary_metric=diseases_eig, top=top)\n",
    "top_pgn = get_top(dictionary_metric=diseases_pgn, top=top)\n",
    "top_deg = get_top(dictionary_metric=diseases_deg, top=top)\n",
    "top_diseases = top_eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure recommendation-strenght (rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define containers of important recommendations\n",
    "rs = list()\n",
    "\n",
    "# Choose a node\n",
    "for disease in top_diseases:\n",
    "\n",
    "    # Get neighbors diseases and neighboring drugs\n",
    "    nei_dis, nei_dru = get_neighbors(graph=dd, node=disease, cats=cats)\n",
    "\n",
    "    # Get max possible weight\n",
    "    ww_max = sum([dd.get_edge_data(disease, nei, 'weight')['weight'] for nei in nei_dis])\n",
    "    \n",
    "    # For every neighboring disease\n",
    "    for n_disease in nei_dis:\n",
    "\n",
    "        # Find all the neighboring drugs \n",
    "        _ , nei_nei_dru = get_neighbors(graph=dd, node=n_disease, cats=cats) \n",
    "\n",
    "        # Chose drugs not in nei_dru\n",
    "        not_in_nei_dru = list(set(nei_nei_dru) - set(nei_dru))\n",
    "\n",
    "        # Add them to rs with weight\n",
    "        c1 = [disease]*len(not_in_nei_dru)\n",
    "        c2 = not_in_nei_dru\n",
    "        ww = dd.get_edge_data(disease, n_disease, 'weight')['weight']\n",
    "        c3 = [ww/ww_max]*len(not_in_nei_dru)\n",
    "        \n",
    "        rs.extend(zip(c1, c2, c3))\n",
    "\n",
    "# Get into a DF\n",
    "rs = pd.DataFrame(data=rs, columns='Disease Drug Recommendation_Strenght'.split())\n",
    "\n",
    "# Group by disease-drug pairs and add the weights\n",
    "rs = pd.DataFrame(rs.groupby('Disease Drug'.split()).sum().reset_index())\n",
    "\n",
    "# Clean duplicates\n",
    "rs = rs.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Add names to mesh_ids\n",
    "rs['Disease_Name'] = [labs[node] for node in rs.Disease]\n",
    "rs['Drug_Name'] = [labs[node] for node in rs.Drug]\n",
    "\n",
    "# Rearrange\n",
    "rs = rs['Disease Disease_Name Drug Drug_Name Recommendation_Strenght'.split()]\n",
    "\n",
    "# Sort by r-strenght\n",
    "rs.sort_values(by='Recommendation_Strenght Disease Drug'.split(), inplace=True, ascending=False)\n",
    "\n",
    "# Reset index\n",
    "rs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Echo\n",
    "print('Size of rs: ', rs.shape)\n",
    "rs.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose input\n",
    "cardinality = 1\n",
    "\n",
    "# Get nodes\n",
    "dis_node = rs['Disease'].iloc[cardinality]\n",
    "dru_node = rs['Drug'].iloc[cardinality]\n",
    "dis_neighs, _ = get_neighbors(graph=ee, node=dis_node, cats=cats)\n",
    "\n",
    "# Gather nodes\n",
    "my_nodes = [dis_node, dru_node]\n",
    "my_nodes.extend(dis_neighs)\n",
    "\n",
    "# Gather categories\n",
    "my_cats={node:cats[node] for node in my_nodes}\n",
    "        \n",
    "# Gather labels\n",
    "my_labs={node:labs[node] for node in my_nodes}\n",
    "\n",
    "# Gather positions\n",
    "eps = 3\n",
    "angle = np.linspace(0, 2*np.pi, len(my_nodes)-2)\n",
    "radius = np.ones(len(my_nodes)-2)\n",
    "x_pos, y_pos = radius*np.cos(angle), radius*np.sin(angle)\n",
    "my_poss=dict()\n",
    "my_poss[dis_node]=(0, +eps)\n",
    "my_poss[dru_node]=(0, -eps)\n",
    "for i in range(len(my_nodes)-2):\n",
    "    my_poss[dis_neighs[i]]=(x_pos[i], y_pos[i])\n",
    "\n",
    "# Construct subgraph\n",
    "ee_sub = ee.subgraph(my_nodes)\n",
    "\n",
    "# Modify original node\n",
    "ee_sub.nodes[dis_node]['category']='X'\n",
    "\n",
    "# Export subgraph to gephi\n",
    "nx.write_gexf(ee_sub, 'drug_recommendation_{:07d}.gexf'.format(cardinality))\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "nx.draw_networkx_labels(ee_sub, pos=my_poss, labels=my_labs, font_size=10)\n",
    "nx.draw_networkx(ee_sub, pos=my_poss, node_size=200, node_shape='^', with_labels=False)\n",
    "\n",
    "titulo='Drug recommendation (rank=#{:}, rs={:3.3f})'.format(\n",
    "    cardinality,\n",
    "    rs['Recommendation_Strenght'].iloc[cardinality])\n",
    "axes.set_title(titulo)\n",
    "axes.set_xlim(-1.5,1.5)\n",
    "axes.set_ylim(-3.5,3.5)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig('drug_recommendation_{:07d}.png'.format(cardinality), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomend disease for top drug ['D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read full graph\n",
    "ee = nx.read_gpickle('Gephi_DD.pkl')\n",
    "\n",
    "# Read categories and labels\n",
    "cats = get_categories(graph=ee)\n",
    "labs = get_mesh_headings(graph=ee)\n",
    "\n",
    "# Choose only drug-nodes\n",
    "drugs = get_only(graph=ee, cats=cats, specific_category='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs stats on drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drugs eigenvector centrality\n",
    "drugs_eig = nx.eigenvector_centrality(drugs, max_iter=500, weight='weight')\n",
    "\n",
    "# Drugs PageRank \n",
    "drugs_pgn = nx.pagerank(drugs, alpha=0.9, weight='weight')\n",
    "\n",
    "# Drugs Degree \n",
    "drugs_deg = nx.degree_centrality(drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select n-top drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top-drugs\n",
    "top = 100\n",
    "top_eig = get_top(dictionary_metric=drugs_eig, top=top)\n",
    "top_pgn = get_top(dictionary_metric=drugs_pgn, top=top)\n",
    "top_deg = get_top(dictionary_metric=drugs_deg, top=top)\n",
    "top_drugs = top_eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute recommendation-strenght (rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define containers of important recommendations\n",
    "rs = list()\n",
    "\n",
    "# Choose a node\n",
    "for drug in top_drugs:\n",
    "\n",
    "    # Get neighbors diseases and neighboring drugs\n",
    "    nei_dru, nei_dis = get_neighbors(graph=dd, node=drug, cats=cats)\n",
    "\n",
    "    # Get max possible weight\n",
    "    ww_max = sum([dd.get_edge_data(drug, nei, 'weight')['weight'] for nei in nei_dru])\n",
    "    \n",
    "    # For every neighboring drug\n",
    "    for n_drug in nei_dru:\n",
    "\n",
    "        # Find all the neighboring diseases \n",
    "        _, nei_nei_dis = get_neighbors(graph=dd, node=n_drug, cats=cats) \n",
    "\n",
    "        # Chose disease not in nei_dis\n",
    "        not_in_nei_dis = list(set(nei_nei_dis) - set(nei_dis))\n",
    "\n",
    "        # Add them to rs with weight\n",
    "        c1 = [drug]*len(not_in_nei_dis)\n",
    "        c2 = not_in_nei_dis\n",
    "        ww = dd.get_edge_data(drug, n_drug, 'weight')['weight']\n",
    "        c3 = [ww/ww_max]*len(not_in_nei_dis)\n",
    "        \n",
    "        rs.extend(zip(c1, c2, c3))\n",
    "\n",
    "\n",
    "# Get into a DF\n",
    "rs = pd.DataFrame(data=rs, columns='Drug Disease Recommendation_Strenght'.split())\n",
    "\n",
    "# Group by disease-drug pairs and add the weights\n",
    "rs = pd.DataFrame(rs.groupby('Drug Disease'.split()).sum().reset_index())\n",
    "\n",
    "# Clean duplicates\n",
    "rs = rs.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Add names to mesh_ids\n",
    "rs['Drug_Name'] = [labs[node] for node in rs.Drug]\n",
    "rs['Disease_Name'] = [labs[node] for node in rs.Disease]\n",
    "\n",
    "# Rearrange\n",
    "rs = rs['Drug Drug_Name Disease Disease_Name Recommendation_Strenght'.split()]\n",
    "\n",
    "# Sort by r-strenght\n",
    "rs.sort_values(by='Recommendation_Strenght Drug Disease'.split(), inplace=True, ascending=False)\n",
    "\n",
    "# Reset index\n",
    "rs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Echo\n",
    "print('Size of rs: ', rs.shape)\n",
    "rs.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose input\n",
    "cardinality = 250\n",
    "\n",
    "# Get nodes\n",
    "dru_node = rs['Drug'].iloc[cardinality]\n",
    "dis_node = rs['Disease'].iloc[cardinality]\n",
    "dru_neighs, _ = get_neighbors(graph=ee, node=dru_node, cats=cats)\n",
    "\n",
    "# Gather nodes\n",
    "my_nodes = [dru_node, dis_node]\n",
    "my_nodes.extend(dru_neighs)\n",
    "\n",
    "# Gather categories\n",
    "my_cats={node:cats[node] for node in my_nodes}\n",
    "        \n",
    "# Gather labels\n",
    "my_labs={node:labs[node] for node in my_nodes}\n",
    "\n",
    "# Gather positions\n",
    "eps = 3\n",
    "angle = np.linspace(0, 2*np.pi, len(my_nodes)-2)\n",
    "radius = np.ones(len(my_nodes)-2)\n",
    "x_pos, y_pos = radius*np.cos(angle), radius*np.sin(angle)\n",
    "my_poss=dict()\n",
    "my_poss[dru_node]=(0, +eps)\n",
    "my_poss[dis_node]=(0, -eps)\n",
    "for i in range(len(my_nodes)-2):\n",
    "    my_poss[dru_neighs[i]]=(x_pos[i], y_pos[i])\n",
    "\n",
    "# Construct subgraph\n",
    "ee_sub = ee.subgraph(my_nodes)\n",
    "\n",
    "# Modify original node\n",
    "ee_sub.nodes[dru_node]['category']='X'\n",
    "\n",
    "# Export subgraph to gephi\n",
    "nx.write_gexf(ee_sub, 'second_use_recommendation_{:07d}.gexf'.format(cardinality))\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "nx.draw_networkx_labels(ee_sub, pos=my_poss, labels=my_labs, font_size=10)\n",
    "nx.draw_networkx(ee_sub, pos=my_poss, node_size=200, node_shape='^', with_labels=False)\n",
    "\n",
    "titulo='Drug recommendation (rank=#{:}, rs={:3.3f})'.format(\n",
    "    cardinality,\n",
    "    rs['Recommendation_Strenght'].iloc[cardinality])\n",
    "axes.set_title(titulo)\n",
    "axes.set_xlim(-1.5,1.5)\n",
    "axes.set_ylim(-3.5,3.5)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig('second_use_recommendation_{:07d}.png'.format(cardinality))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
