{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This script  fetches all gse series with Organism=Homo Sapiens of the GEO Database and creates a xml file out of it\n",
    "from Bio import Entrez\n",
    "import time\n",
    "try:\n",
    "    from urllib.error import HTTPError  # for Python 3\n",
    "except ImportError:\n",
    "    from urllib2 import HTTPError  # for Python 2\n",
    "# retmax = maximum number of retrieved series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of found entries: 46608\n",
      "0\n",
      "Going to download record 1 to 5000\n",
      "5000\n",
      "Going to download record 5001 to 10000\n",
      "10000\n",
      "Going to download record 10001 to 15000\n",
      "15000\n",
      "Going to download record 15001 to 20000\n",
      "20000\n",
      "Going to download record 20001 to 25000\n",
      "25000\n",
      "Going to download record 25001 to 30000\n",
      "30000\n",
      "Going to download record 30001 to 35000\n",
      "35000\n",
      "Going to download record 35001 to 40000\n",
      "40000\n",
      "Going to download record 40001 to 45000\n",
      "45000\n",
      "Going to download record 45001 to 46608\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "Entrez.email = 'example.email.12346578901@gmail.com'\n",
    "filenamebase=\"all_gse_series_homo_sapiens\"\n",
    "# filenamebase=\"small_sample_gse_series_homo_sapiens\"\n",
    "\n",
    "# use_small_number_of_series = True when only a small number of series shall be extracted. The number of series is specified by small_number_of_series\n",
    "use_small_number_of_series = False\n",
    "small_number_of_series = 10\n",
    "\n",
    "# if use_id=True then the ids are used to fetch the data but then only one by one they can be extracted.\n",
    "# if use_id=False then the fetching can be performed via larger batchsizes but makes neccesary to perform the initial esearch with usehistory=\"y\" and the fetch with the WebEnv and query_key arguments.\n",
    "use_id = False\n",
    "if(use_id):\n",
    "    batch_size = 1\n",
    "    use_hist_val = 'n'\n",
    "else:\n",
    "    batch_size = 5000\n",
    "    use_hist_val = 'y'\n",
    "\n",
    "\n",
    "handle = Entrez.esearch(db=\"gds\", term=\"GSE[ETYP] AND Homo[Organism]\", retmax=small_number_of_series, usehistory=use_hist_val)\n",
    "record = Entrez.read(handle)\n",
    "total_n_series = int(record['Count'])\n",
    "if(not(use_small_number_of_series and not(use_id))):\n",
    "    handle.close()\n",
    "\n",
    "if(not use_small_number_of_series):\n",
    "    handle = Entrez.esearch(db=\"gds\", term=\"GSE[ETYP] AND Homo[Organism]\", retmax=total_n_series, usehistory=use_hist_val)\n",
    "    record = Entrez.read(handle)\n",
    "    if(use_id):\n",
    "        handle.close()\n",
    "\n",
    "idlist = record['IdList']\n",
    "count = int(len(idlist))\n",
    "print('Total number of found entries: ' + str(count))\n",
    "\n",
    "\n",
    "for start in range(0, count, batch_size):\n",
    "    print(start)\n",
    "    if batch_size == 1:\n",
    "        end = start\n",
    "        if(use_id):\n",
    "            ival = start\n",
    "    else:\n",
    "        end = min(count, start + batch_size)\n",
    "        if(use_id):\n",
    "            ival = slice(start, end, 1)\n",
    "    if(use_id):\n",
    "        print(\"Going to download record with id {}\".format(idlist[ival]))\n",
    "    else:\n",
    "        print(\"Going to download record %i to %i\" % (start+1, end))\n",
    "    attempt = 1\n",
    "    not_fetched = True\n",
    "    while ((attempt <= 3) and not_fetched):\n",
    "        try:\n",
    "            if(use_id):\n",
    "                fetch_handle = Entrez.esummary(db=\"gds\", id=idlist[ival], retmode=\"xml\")\n",
    "            else:\n",
    "                fetch_handle = Entrez.esummary(db=\"gds\", retstart=start, retmax=min(10000, batch_size), retmode=\"xml\", webenv=record['WebEnv'], query_key=record['QueryKey'])\n",
    "            data = fetch_handle.read()\n",
    "            \n",
    "            fetch_handle.close()\n",
    "\n",
    "            out_handle = open(filenamebase+\"_part\"+str(int(start/batch_size))+\".xml\", \"a\")\n",
    "            out_handle.write(data)\n",
    "            out_handle.close()\n",
    "\n",
    "            not_fetched = False\n",
    "        except HTTPError as err:\n",
    "            not_fetched = True\n",
    "            if 500 <= err.code <= 599:\n",
    "                print(\"Received error from server %s\" % err)\n",
    "                print(\"Attempt %i of 3\" % attempt)\n",
    "                attempt += 1\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
