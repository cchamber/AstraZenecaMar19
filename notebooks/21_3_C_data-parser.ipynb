{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# XML parsing \n",
    "In this file we will parse the xml data files\n",
    "\n",
    "1. First we loop through xml files and get a very long list of dictionaries\n",
    "2. We turn the list of dictionaries into a python data frame\n",
    "3. Then we get the data for the sample, stored in subdictionaries in the 'Samples' field of the main dataframe\n",
    "4. Number of samples to the records df\n",
    "5. Output is saved two dataframes, converted to pkl files, in the same folder as the raw data files:\n",
    "    - records_df --> records.pkl\n",
    "    - samples_df --> samples.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Parsing raw data\n",
    "- First we loop through xml files and get a very long list of dictionaries.\n",
    "- We turn the list of dictionaries into a pandas data frame.\n",
    "- Then we go through each row of the larger dataframe and get the sample data from each row (takes a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Entrez.email = \"A.N.Other@example.com\" # Always tell NCBI who you are\n",
    "\n",
    "data_path = '../data/raw' # rename with template\n",
    "output_data_path = '../data/records_samples' # rename with template\n",
    "file_base_name = \"all_gse_series_homo_sapiens_part\"\n",
    "output_file_rec = os.path.join(output_data_path, 'records.pkl')\n",
    "output_file_sam = os.path.join(output_data_path, 'samples.pkl')\n",
    "raw_files = sorted(glob.glob(os.path.join(data_path, file_base_name+'*')))\n",
    "\n",
    "if os.path.isdir(output_data_path)!=1:\n",
    "    os.mkdir(output_data_path)\n",
    "\n",
    "record_list = []\n",
    "for ifile in raw_files:\n",
    "    print('Parsing ',ifile)\n",
    "    handle = open(ifile)\n",
    "    records = Entrez.parse(handle)\n",
    "    for record in records:\n",
    "        record_list.append(record)\n",
    "        \n",
    "records_df = pd.DataFrame(record_list)\n",
    "\n",
    "samples_df = pd.DataFrame()\n",
    "for i in range(len(records_df)):\n",
    "    samples_aux = pd.DataFrame(records_df.loc[i].Samples)\n",
    "    samples_aux['Id'] = records_df.loc[i].Id\n",
    "    samples_aux['nsamples'] = len(samples_aux)\n",
    "    samples_df = samples_df.append(samples_aux)\n",
    "    if i%5000==0:\n",
    "        print('Sample iteration:')\n",
    "        print(i)\n",
    "\n",
    "samples_df = samples_df.set_index(['Id','nsamples'])\n",
    "print('Saving samples to ', output_file_sam)\n",
    "samples_df.to_pickle(output_file_sam)\n",
    "\n",
    "# take sample count from samples and put in records\n",
    "samples_df['dum'] = 1\n",
    "n_samples_df = samples_df.reset_index().groupby(['Id','nsamples']).mean().reset_index()\n",
    "records_df = pd.merge(n_samples_df[['Id','nsamples']],records_df, on='Id', how='right')\n",
    "\n",
    "print('')\n",
    "print('Saving records to ', output_file_rec)\n",
    "print('')\n",
    "records_df.to_pickle(output_file_rec)\n",
    "\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
